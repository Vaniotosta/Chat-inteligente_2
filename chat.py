# -*- coding: utf-8 -*-
"""Ves√£o 12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fwTVHCMSTfwmbmF42jcopznLz3bA70Wp

# 1. Instalar depend√™ncias
"""

!pip install langchain langchain-community langchain-huggingface faiss-cpu fastapi uvicorn nest-asyncio pyngrok pandas

"""# 2. Banco SQLite (igual antes)"""

import sqlite3

DB_PATH = "chat_history.db"

def init_db():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            agent TEXT,
            user TEXT,
            message TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()

def save_message(agent: str, user: str, message: str):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("INSERT INTO messages (agent, user, message) VALUES (?, ?, ?)",
                (agent, user, message))
    conn.commit()
    conn.close()

def get_history():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    rows = cur.execute(
        "SELECT id, agent, user, message, timestamp FROM messages ORDER BY id ASC"
    ).fetchall()
    conn.close()
    return [
        {"id": r[0], "agent": r[1], "user": r[2], "message": r[3], "timestamp": r[4]}
        for r in rows
    ]

init_db()

"""# 3. Agente Cat√°logo com LangChain"""

import pandas as pd
import json
from langchain.tools import tool

class CatalogAgent:
    def __init__(self, json_path: str):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        self.df = pd.DataFrame(data)
        # Detecta coluna do nome do produto
        possible_cols = ["productId", "price", "title", "image","description"]
        self.name_col = None
        for c in self.df.columns:
            if c.lower() in [p.lower() for p in possible_cols]:
                self.name_col = c
                break
        if not self.name_col:
            raise ValueError(f"N√£o encontrei coluna de produto em {list(self.df.columns)}")

    @tool("buscar_produto", return_direct=True)
    def search(self, query: str, top_k: int = 5):
        """Busca produtos no cat√°logo pelo nome"""
        mask = self.df[self.name_col].astype(str).str.contains(query, case=False, na=False)
        results = self.df[mask].head(top_k)
        return results.to_dict(orient="records")

cat_agent = CatalogAgent("dados-produtos.json")



"""# 4. Agente SAC com LangChain (RAG)
Aqui usamos langchain + embeddings + FAISS.
"""

from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.llms import HuggingFacePipeline
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch

# carregar modelo pequeno Qwen
model_name = "Qwen/Qwen2.5-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
qwen_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

pipe = pipeline(
    "text-generation",
    model=qwen_model,
    tokenizer=tokenizer,
    max_new_tokens=200
)

llm = HuggingFacePipeline(pipeline=pipe)

# processar base SAC
with open("dados-sac.md", "r", encoding="utf-8") as f:
    sac_text = f.read()

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = splitter.create_documents([sac_text])

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(docs, embeddings)

retriever = vectorstore.as_retriever()

# chain de RAG
template = """Voc√™ √© um atendente de SAC. Responda de forma objetiva com base no contexto.
Contexto: {context}
Pergunta: {question}
Resposta:"""

prompt = PromptTemplate(template=template, input_variables=["context", "question"])

sac_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

print(sac_chain.invoke("Qual o prazo de reembolso?"))

"""#5. API RESTful com FastAPI"""

from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="Chat Inteligente com LangChain")

class Message(BaseModel):
    user: str
    agent: str   # "sac" ou "catalog"
    message: str

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/chat")
def chat(msg: Message):
    save_message(msg.agent, msg.user, msg.message)

    if msg.agent == "catalog":
        # Correctly invoke the tool
        result = cat_agent.search.invoke(msg.message)
        save_message("catalog", "bot", str(result))
        return {"agent": "catalog", "results": result}

    if msg.agent == "sac":
        result = sac_chain.invoke(msg.message)['result']
        save_message("sac", "bot", result)
        return {"agent": "sac", "response": result}

@app.get("/history")
def history():
    return {"history": get_history()}

"""# 6. Rodar API com ngrok"""

from google.colab import userdata
userdata.get('grou')

import nest_asyncio, uvicorn
from pyngrok import ngrok
import threading
from google.colab import userdata

nest_asyncio.apply()

# Get the authtoken from Colab Secrets
NGROK_AUTH_TOKEN = userdata.get('grou')
if NGROK_AUTH_TOKEN:
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
else:
    print("NGROK_AUTH_TOKEN not found in Colab Secrets. Please add it.")

public_url = ngrok.connect(8000)
print("üöÄ Sua API est√° dispon√≠vel em:", public_url)

def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

thread = threading.Thread(target=run, daemon=True)
thread.start()

"""#  Endpoints RESTful
Health check
"""

!curl -s https://728bd1e325f9.ngrok-free.app/health

"""# Chat SAC"""

# Replace https://SEU_LINK_NGROK with your actual ngrok URL from the output of the cell above
!curl -s -X POST https://728bd1e325f9.ngrok-free.app/chat \
 -H "Content-Type: application/json" \
 -d '{"user":"Ana","agent":"sac","message":"Qual √© o prazo para reembolso?"}'

"""# Hist√≥rico"""

!curl -s https://728bd1e325f9.ngrok-free.app/history